{"paragraphs":[{"text":"%dep\n\nz.load(\"org.apache.spark:spark-streaming_2.10:1.6.2\")\nz.load(\"org.apache.spark:spark-streaming-twitter_2.10:1.6.2\")\nz.load(\"org.twitter4j:twitter4j-core:4.0.5\")\n","dateUpdated":"2017-01-16T11:19:12-0500","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1484583552725_736628444","id":"20160830-145728_362255206","dateCreated":"2017-01-16T11:19:12-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16917"},{"text":"%md\n\n<p>\nDevelop a Spark Streaming application that picks up Twitter postings containing hashtags matching any of the following words\n</p>\n\n<p>\n<b>\n\"xap\", \"insightedge\", \"nodejs\", \"docker\", \"tdd\", \"java\", \"scala\", \"ruby\", \"golang\"\n</b>\n</p>\n\n<p>\nand prints a count for each hashtag of the tweets mentioning that word.\n</p>","dateUpdated":"2017-01-16T01:17:10-0500","config":{"colWidth":12,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true,"editorMode":"ace/mode/markdown","editorHide":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1484590614192_-1735701831","id":"20170116-131654_997844638","result":{"code":"SUCCESS","type":"HTML","msg":"<p>\nDevelop a Spark Streaming application that picks up Twitter postings containing hashtags matching any of the following words\n</p>\n<p>\n<b>\n\"xap\", \"insightedge\", \"nodejs\", \"docker\", \"tdd\", \"java\", \"scala\", \"ruby\", \"golang\"\n</b>\n</p>\n<p>\nand prints a count for each hashtag of the tweets mentioning that word.\n</p>\n"},"dateCreated":"2017-01-16T01:16:54-0500","dateStarted":"2017-01-16T01:17:09-0500","dateFinished":"2017-01-16T01:17:09-0500","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16918"},{"title":"Solution","text":"%spark\n\nimport org.apache.spark._\nimport org.apache.spark.streaming._\nimport org.apache.spark.streaming.twitter._\nimport org.apache.spark.storage.StorageLevel\n\nval consumerKey = \"aXbCpq9Zru7UimHAfnzVA\"\nval consumerSecret = \"NlXxNAv1hHR9RUxm5o9WMiSBnzNJV7RpWGzffixKQ\"\nval accessToken = \"28462935-f9vhPSCfDd6BlMefL4hbReDgbLp1c6FME72nJIlIi\"\nval accessTokenSecret = \"nELm7MW28sBhJt7F3lqQr0pWVnCzrewMmx3WFlq2W0\"\n\nSystem.setProperty(\"twitter4j.oauth.consumerKey\", consumerKey)\nSystem.setProperty(\"twitter4j.oauth.consumerSecret\", consumerSecret)\nSystem.setProperty(\"twitter4j.oauth.accessToken\", accessToken)\nSystem.setProperty(\"twitter4j.oauth.accessTokenSecret\", accessTokenSecret)\n\nval ssc = new StreamingContext(sc, Seconds(15))\nssc.checkpoint(\"c:/tmp/checkpoint\")\n\nval filters = Seq(\"xap\", \"insightedge\", \"nodejs\", \"docker\", \"tdd\", \"java\", \"scala\", \"ruby\", \"golang\")\n\nval tweets = TwitterUtils.createStream(ssc, None, filters, StorageLevel.MEMORY_ONLY_SER_2)\n\nval tweetsFilteredByLang = tweets.filter(t => t.getLang() == \"en\")\n\nval statuses = tweetsFilteredByLang.map(t => t.getText())\n\nval words = statuses.flatMap{status => status.split(\"\"\"\\s+\"\"\")}\n\nval hashTags = words.filter{word => word.startsWith(\"#\")}\n\nval hashTagPairs = hashTags.map{hashtag => (hashtag, 1)}\n\nval tagsWithCounts = hashTagPairs.updateStateByKey( (counts: Seq[Int], prevCount: Option[Int]) =>\n    prevCount.map{c => c + counts.sum}.orElse{Some(counts.sum)}\n)\n\ntagsWithCounts.print()\n\nssc.start()\n","dateUpdated":"2017-01-16T01:17:06-0500","config":{"tableHide":false,"colWidth":12,"editorMode":"ace/mode/scala","title":true,"graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1484583552726_737782691","id":"20160825-135423_1775581826","dateCreated":"2017-01-16T11:19:12-0500","dateStarted":"2017-01-16T11:21:08-0500","dateFinished":"2017-01-16T11:21:21-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16919"},{"text":"%spark\n\nssc.stop(stopSparkContext=false, stopGracefully=true)\n","dateUpdated":"2017-01-16T11:21:45-0500","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1484583552726_737782691","id":"20160825-133825_16834077","dateCreated":"2017-01-16T11:19:12-0500","dateStarted":"2017-01-16T11:21:45-0500","dateFinished":"2017-01-16T11:22:15-0500","status":"FINISHED","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16920"},{"dateUpdated":"2017-01-16T11:19:12-0500","config":{"colWidth":12,"editorMode":"ace/mode/scala","graph":{"mode":"table","height":300,"optionOpen":false,"keys":[],"values":[],"groups":[],"scatter":{}},"enabled":true},"settings":{"params":{},"forms":{}},"jobName":"paragraph_1484583552727_737397942","id":"20160830-151349_1041624973","dateCreated":"2017-01-16T11:19:12-0500","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16921"}],"name":"Spark Streaming - Exercise 1 Solution","id":"2C8QYPDV7","angularObjects":{"2C14DCYPT:shared_process":[],"2BXE9YPBX:shared_process":[]},"config":{"looknfeel":"default"},"info":{}}